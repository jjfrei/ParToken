% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ParToken_functions.R
\name{tokenize_dataset}
\alias{tokenize_dataset}
\title{Parallel tokenize a dataset directly}
\usage{
tokenize_dataset(
  path,
  data_type = "csv",
  text = "text",
  unit = "word",
  language = "en",
  preprocess = TRUE
)
}
\arguments{
\item{path}{path to your dataset}

\item{data_type}{what kind of data type is the dataset}

\item{text}{which column of the ds has the text in it}

\item{unit}{tokenize by which unit "word" or "sentence"}

\item{language}{language of the stop words}

\item{preprocess}{should the tokens be preprocessed? TRUE or FALSE}
}
\value{
tokens
}
\description{
Parallel tokenize a dataset directly
}
\examples{
pre_tokens <- tokenize_dataset(path = "PPE_party.csv", text = "fused", preprocess = FALSE)
}
