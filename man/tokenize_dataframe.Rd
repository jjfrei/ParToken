% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ParToken_functions.R
\name{tokenize_dataframe}
\alias{tokenize_dataframe}
\title{Parallel tokenize an df}
\usage{
tokenize_dataframe(
  df,
  text = "text",
  unit = "word",
  language = "en",
  preprocess = TRUE
)
}
\arguments{
\item{df}{df you want to tokenize}

\item{text}{which column of the ds has the text in it}

\item{unit}{tokenize by which unit "word" or "sentence"}

\item{language}{language of the stop words}

\item{preprocess}{should the tokens be preprocessed? TRUE or FALSE}
}
\value{
tokens
}
\description{
Parallel tokenize an df
}
\examples{
pre_tokens <- tokenize_dataframe(path = "PPE_party.csv", text = "fused", preprocess = FALSE)
}
